{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train your movie recommendation model in Amazon Personalize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook shows how you can train a machine learning model with Amazon Personalize which can recommend movies to users based on a movie which they liked.\n",
    "\n",
    "We will use the MovieLens 20m data set to train our model.  MovieLens is a well-known dataset storing movie ratings. It comes in different sizes and formats: here, we will use ml-20m, which contains 20 million ratings applied to 27,000 movies by 138,000 users, see https://grouplens.org/datasets/movielens/. \n",
    "\n",
    "In order to create a machine learning model we need to execute following steps:\n",
    "\n",
    "1. Prepare the data so it can be imported into Amazon Personalize\n",
    "2. Create a DataSet Group and configure an import job for the data set to import the data into Amazon Personalize\n",
    "3. Train and evaluate our model by creating a solution and solution version\n",
    "4. Validate our model performance and deploy an endpoint which can serve predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "First import libraries required in this notebook and do some basic initializations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import boto3, os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import sagemaker\n",
    "from sklearn.utils import shuffle\n",
    "os.environ['AWS_DEFAULT_REGION']=\"us-east-1\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create a new s3 bucket to store our data and assets required for the chatbot. The bucket has the name movie-chatbot-resources-<account_number>. Overwrite this if you want another name!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': '81849D974D489B7E',\n",
       "  'HostId': 'd7YdIT1Rk9o1SCokpxFKTNv84mlszFaf4N+xHE3oD8MMVbPn9PWE0aypMW6xzv5Akq7/9AYmf5Q=',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amz-id-2': 'd7YdIT1Rk9o1SCokpxFKTNv84mlszFaf4N+xHE3oD8MMVbPn9PWE0aypMW6xzv5Akq7/9AYmf5Q=',\n",
       "   'x-amz-request-id': '81849D974D489B7E',\n",
       "   'date': 'Mon, 06 Jan 2020 13:13:48 GMT',\n",
       "   'location': '/movie-chatbot-resources-190920649605',\n",
       "   'content-length': '0',\n",
       "   'server': 'AmazonS3'},\n",
       "  'RetryAttempts': 0},\n",
       " 'Location': '/movie-chatbot-resources-190920649605'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sts = boto3.client('sts')\n",
    "s3 = boto3.client('s3')\n",
    "personalize = boto3.client('personalize')\n",
    "\n",
    "accountId = sts.get_caller_identity()[\"Account\"]\n",
    "bucket = 'movie-chatbot-resources-' + accountId\n",
    "s3.create_bucket(Bucket=bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file name for files containg rating\n",
    "filename_ratings = \"ratings.csv\"\n",
    "# file name for file containing movie title to ID mapping\n",
    "filename_movies = \"movies.csv\"\n",
    "\n",
    "suffix= \"20m\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download and process data\n",
    "\n",
    "Once we’ve downloaded and unzipped the dataset, let’s load the ‘ratings.csv’ file and apply the following processing:\n",
    "\n",
    "- Shuffle reviews.\n",
    "- Keep only movies rated 4 and above, and drop the ratings columns: In our use case we just want our model to recommend movies that users should really like.\n",
    "- Rename columns to the names used in the schema.\n",
    "- Keep only 1,000,000 interactions to minimize training time (this is just a demo after all!).\n",
    "\n",
    "We can achieve this with standard functionality in [Pandas](https://pandas.pydata.org/) and [SciKit-Learn](https://scikit-learn.org/stable/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  189M  100  189M    0     0  21.5M      0  0:00:08  0:00:08 --:--:-- 23.6M\n",
      "Archive:  ml-20m.zip\n",
      "   creating: ml-20m/\n",
      "  inflating: ml-20m/genome-scores.csv  \n",
      "  inflating: ml-20m/genome-tags.csv  \n",
      "  inflating: ml-20m/links.csv        \n",
      "  inflating: ml-20m/movies.csv       \n",
      "  inflating: ml-20m/ratings.csv      \n",
      "  inflating: ml-20m/README.txt       \n",
      "  inflating: ml-20m/tags.csv         \n"
     ]
    }
   ],
   "source": [
    "!curl -O http://files.grouplens.org/datasets/movielens/ml-20m.zip\n",
    "!unzip -o ml-20m.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>USER_ID</th>\n",
       "      <th>ITEM_ID</th>\n",
       "      <th>RATING</th>\n",
       "      <th>TIMESTAMP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1112486027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1112484676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1112484819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1112484727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1112484580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20000258</th>\n",
       "      <td>138493</td>\n",
       "      <td>68954</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1258126920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20000259</th>\n",
       "      <td>138493</td>\n",
       "      <td>69526</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1259865108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20000260</th>\n",
       "      <td>138493</td>\n",
       "      <td>69644</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1260209457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20000261</th>\n",
       "      <td>138493</td>\n",
       "      <td>70286</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1258126944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20000262</th>\n",
       "      <td>138493</td>\n",
       "      <td>71619</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1255811136</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000263 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          USER_ID  ITEM_ID  RATING   TIMESTAMP\n",
       "0               1        2     3.5  1112486027\n",
       "1               1       29     3.5  1112484676\n",
       "2               1       32     3.5  1112484819\n",
       "3               1       47     3.5  1112484727\n",
       "4               1       50     3.5  1112484580\n",
       "...           ...      ...     ...         ...\n",
       "20000258   138493    68954     4.5  1258126920\n",
       "20000259   138493    69526     4.5  1259865108\n",
       "20000260   138493    69644     3.0  1260209457\n",
       "20000261   138493    70286     5.0  1258126944\n",
       "20000262   138493    71619     2.5  1255811136\n",
       "\n",
       "[20000263 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings = pd.read_csv('./ml-20m/ratings.csv', header=0, names=['USER_ID','ITEM_ID','RATING','TIMESTAMP'])\n",
    "pd.set_option('display.max_rows', 10)\n",
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique users 125388; unique items 13219\n"
     ]
    }
   ],
   "source": [
    "data = shuffle(ratings)\n",
    "data = data[data['RATING'] > 3.5 ] # Only take \"good\" movies into account\n",
    "data = data.drop(columns='RATING') # Drop ratings column to simplify training\n",
    "data = data[:1000000] # Only use first million ratings to improve training speed\n",
    "\n",
    "print('unique users %d; unique items %d'%(\n",
    "    len(data['USER_ID'].unique()), len(data['ITEM_ID'].unique())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The movies.dat file contains the mapping of item ids to movie names. We will need this later in our chat bot lambda function to map movie titles back to IDs. As we have stripped down the size of interactions to 1,000,000 we will strip out movies that have no ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ITEM_ID</th>\n",
       "      <th>title</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>Comedy|Drama|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27132</th>\n",
       "      <td>130512</td>\n",
       "      <td>Hippocrates (2014)</td>\n",
       "      <td>Comedy|Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27178</th>\n",
       "      <td>130960</td>\n",
       "      <td>The Conrad Boys (2006)</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27201</th>\n",
       "      <td>131050</td>\n",
       "      <td>Stargate SG-1 Children of the Gods - Final Cut...</td>\n",
       "      <td>Adventure|Sci-Fi|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27249</th>\n",
       "      <td>131148</td>\n",
       "      <td>What A Man (2011)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27271</th>\n",
       "      <td>131250</td>\n",
       "      <td>No More School (2000)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13219 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ITEM_ID                                              title  \\\n",
       "0            1                                   Toy Story (1995)   \n",
       "1            2                                     Jumanji (1995)   \n",
       "2            3                            Grumpier Old Men (1995)   \n",
       "3            4                           Waiting to Exhale (1995)   \n",
       "4            5                 Father of the Bride Part II (1995)   \n",
       "...        ...                                                ...   \n",
       "27132   130512                                 Hippocrates (2014)   \n",
       "27178   130960                             The Conrad Boys (2006)   \n",
       "27201   131050  Stargate SG-1 Children of the Gods - Final Cut...   \n",
       "27249   131148                                  What A Man (2011)   \n",
       "27271   131250                              No More School (2000)   \n",
       "\n",
       "                                             genre  \n",
       "0      Adventure|Animation|Children|Comedy|Fantasy  \n",
       "1                       Adventure|Children|Fantasy  \n",
       "2                                   Comedy|Romance  \n",
       "3                             Comedy|Drama|Romance  \n",
       "4                                           Comedy  \n",
       "...                                            ...  \n",
       "27132                                 Comedy|Drama  \n",
       "27178                                        Drama  \n",
       "27201                    Adventure|Sci-Fi|Thriller  \n",
       "27249                               Comedy|Romance  \n",
       "27271                                       Comedy  \n",
       "\n",
       "[13219 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies = pd.read_csv('./ml-20m/movies.csv', header=0, names=['ITEM_ID','title','genre'])\n",
    "uniqueMovieIds = data['ITEM_ID'].unique() # get unique movie ID'S\n",
    "movies = movies[movies.ITEM_ID.isin(uniqueMovieIds)]  # filter movies which are not used in the data\n",
    "movies\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload data\n",
    "\n",
    "We will upload the preprocessed data to S3 in order to be able to import to Amazon Personalize later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(filename_ratings, index=False)\n",
    "movies.to_csv(filename_movies, index=False)\n",
    "\n",
    "boto3.Session().resource('s3').Bucket(bucket).Object(filename_ratings ).upload_file(filename_ratings)\n",
    "boto3.Session().resource('s3').Bucket(bucket).Object(filename_movies ).upload_file(filename_movies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configure permissions for import\n",
    "\n",
    "Attach a bucket policy that allows Amazon Personalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.client(\"s3\")\n",
    "\n",
    "policy = {\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Id\": \"PersonalizeS3BucketAccessPolicy\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Sid\": \"PersonalizeS3BucketAccessPolicy\",\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Principal\": {\n",
    "                \"Service\": \"personalize.amazonaws.com\"\n",
    "            },\n",
    "            \"Action\": [\n",
    "                \"s3:GetObject\",\n",
    "                \"s3:ListBucket\"\n",
    "            ],\n",
    "            \"Resource\": [\n",
    "                \"arn:aws:s3:::{}\".format(bucket),\n",
    "                \"arn:aws:s3:::{}/*\".format(bucket)\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "s3.put_bucket_policy(Bucket=bucket, Policy=json.dumps(policy));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:iam::190920649605:role/PersonalizeS3Role-20m\n"
     ]
    }
   ],
   "source": [
    "from botocore.exceptions import ClientError\n",
    "iam = boto3.client(\"iam\")\n",
    "\n",
    "role_name = \"PersonalizeS3Role-\"+suffix\n",
    "assume_role_policy_document = {\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "          \"Effect\": \"Allow\",\n",
    "          \"Principal\": {\n",
    "            \"Service\": \"personalize.amazonaws.com\"\n",
    "          },\n",
    "          \"Action\": \"sts:AssumeRole\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "try:\n",
    "    create_role_response = iam.create_role(\n",
    "        RoleName = role_name,\n",
    "        AssumeRolePolicyDocument = json.dumps(assume_role_policy_document)\n",
    "    );\n",
    "    role_arn = create_role_response[\"Role\"][\"Arn\"]\n",
    "except ClientError as e:\n",
    "    if e.response['Error']['Code'] == 'EntityAlreadyExists':\n",
    "        role_arn = iam.get_role(RoleName=role_name)['Role']['Arn']\n",
    "    else:\n",
    "        raise\n",
    "iam.attach_role_policy(\n",
    "    RoleName = role_name,\n",
    "    PolicyArn = \"arn:aws:iam::aws:policy/AmazonS3ReadOnlyAccess\"\n",
    ");\n",
    "print(role_arn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Schema\n",
    "\n",
    "Now create a schema in Amazon Personalize which describes the data format, see https://docs.aws.amazon.com/personalize/latest/dg/how-it-works-dataset-schema.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"schemaArn\": \"arn:aws:personalize:us-east-1:190920649605:schema/DEMO-sims-schema20m\",\n",
      "  \"ResponseMetadata\": {\n",
      "    \"RequestId\": \"604fc04a-287a-4143-af6d-988a01bdebf9\",\n",
      "    \"HTTPStatusCode\": 200,\n",
      "    \"HTTPHeaders\": {\n",
      "      \"content-type\": \"application/x-amz-json-1.1\",\n",
      "      \"date\": \"Mon, 06 Jan 2020 13:14:22 GMT\",\n",
      "      \"x-amzn-requestid\": \"604fc04a-287a-4143-af6d-988a01bdebf9\",\n",
      "      \"content-length\": \"85\",\n",
      "      \"connection\": \"keep-alive\"\n",
      "    },\n",
      "    \"RetryAttempts\": 0\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "schema = {\n",
    "    \"type\": \"record\",\n",
    "    \"name\": \"Interactions\",\n",
    "    \"namespace\": \"com.amazonaws.personalize.schema\",\n",
    "    \"fields\": [\n",
    "        {\n",
    "            \"name\": \"USER_ID\",\n",
    "            \"type\": \"string\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"ITEM_ID\",\n",
    "            \"type\": \"string\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"TIMESTAMP\",\n",
    "            \"type\": \"long\"\n",
    "        }\n",
    "    ],\n",
    "    \"version\": \"1.0\"\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "create_schema_response = personalize.create_schema(\n",
    "    name = \"DEMO-sims-schema\"+suffix,\n",
    "    schema = json.dumps(schema)\n",
    ")\n",
    "\n",
    "schema_arn = create_schema_response['schemaArn']\n",
    "print(json.dumps(create_schema_response, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create and Wait for Dataset Group creation\n",
    "\n",
    "First we create a Dataset Group in Amazon Personalize. A DataSet group is a container which contains all required data and Amazon Personalize objects for a specific use case. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"datasetGroupArn\": \"arn:aws:personalize:us-east-1:190920649605:dataset-group/DEMO-sims-dataset-group-20m\",\n",
      "  \"ResponseMetadata\": {\n",
      "    \"RequestId\": \"837f37f9-2240-49c9-bbb2-cfa446298d73\",\n",
      "    \"HTTPStatusCode\": 200,\n",
      "    \"HTTPHeaders\": {\n",
      "      \"content-type\": \"application/x-amz-json-1.1\",\n",
      "      \"date\": \"Mon, 06 Jan 2020 13:14:23 GMT\",\n",
      "      \"x-amzn-requestid\": \"837f37f9-2240-49c9-bbb2-cfa446298d73\",\n",
      "      \"content-length\": \"106\",\n",
      "      \"connection\": \"keep-alive\"\n",
      "    },\n",
      "    \"RetryAttempts\": 0\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "create_dataset_group_response = personalize.create_dataset_group(\n",
    "    name = \"DEMO-sims-dataset-group-\"+suffix\n",
    ")\n",
    "\n",
    "dataset_group_arn = create_dataset_group_response['datasetGroupArn']\n",
    "print(json.dumps(create_dataset_group_response, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetGroup: CREATE PENDING\n",
      "DatasetGroup: ACTIVE\n",
      "CPU times: user 8.89 ms, sys: 523 µs, total: 9.42 ms\n",
      "Wall time: 20.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "status = None\n",
    "max_time = time.time() + 3*60*60 # 3 hours\n",
    "while time.time() < max_time:\n",
    "    describe_dataset_group_response = personalize.describe_dataset_group(\n",
    "        datasetGroupArn = dataset_group_arn\n",
    "    )\n",
    "    status = describe_dataset_group_response[\"datasetGroup\"][\"status\"]\n",
    "    print(\"DatasetGroup: {}\".format(status))\n",
    "    \n",
    "    if status == \"ACTIVE\" or status == \"CREATE FAILED\":\n",
    "        break\n",
    "        \n",
    "    time.sleep(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare, Create, and Wait for Dataset Import Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"datasetArn\": \"arn:aws:personalize:us-east-1:190920649605:dataset/DEMO-sims-dataset-group-20m/INTERACTIONS\",\n",
      "  \"ResponseMetadata\": {\n",
      "    \"RequestId\": \"0348e5b0-c033-4265-9318-f75a5b2b9e0a\",\n",
      "    \"HTTPStatusCode\": 200,\n",
      "    \"HTTPHeaders\": {\n",
      "      \"content-type\": \"application/x-amz-json-1.1\",\n",
      "      \"date\": \"Mon, 06 Jan 2020 13:14:43 GMT\",\n",
      "      \"x-amzn-requestid\": \"0348e5b0-c033-4265-9318-f75a5b2b9e0a\",\n",
      "      \"content-length\": \"108\",\n",
      "      \"connection\": \"keep-alive\"\n",
      "    },\n",
      "    \"RetryAttempts\": 0\n",
      "  }\n",
      "}\n",
      "CPU times: user 4.12 ms, sys: 6 µs, total: 4.13 ms\n",
      "Wall time: 29.7 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dataset_type = \"INTERACTIONS\"\n",
    "create_dataset_response = personalize.create_dataset(\n",
    "    datasetType = dataset_type,\n",
    "    datasetGroupArn = dataset_group_arn,\n",
    "    schemaArn = schema_arn,\n",
    "    name = \"DEMO-sims-dataset-\"+suffix\n",
    ")\n",
    "\n",
    "dataset_arn = create_dataset_response['datasetArn']\n",
    "print(json.dumps(create_dataset_response, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"datasetImportJobArn\": \"arn:aws:personalize:us-east-1:190920649605:dataset-import-job/DEMO-sims-dataset-import-job-20m\",\n",
      "  \"ResponseMetadata\": {\n",
      "    \"RequestId\": \"4c195c4c-6ee0-401f-81ad-e8e58fa33074\",\n",
      "    \"HTTPStatusCode\": 200,\n",
      "    \"HTTPHeaders\": {\n",
      "      \"content-type\": \"application/x-amz-json-1.1\",\n",
      "      \"date\": \"Mon, 06 Jan 2020 13:14:43 GMT\",\n",
      "      \"x-amzn-requestid\": \"4c195c4c-6ee0-401f-81ad-e8e58fa33074\",\n",
      "      \"content-length\": \"120\",\n",
      "      \"connection\": \"keep-alive\"\n",
      "    },\n",
      "    \"RetryAttempts\": 0\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "create_dataset_import_job_response = personalize.create_dataset_import_job(\n",
    "    jobName = \"DEMO-sims-dataset-import-job-\"+suffix,\n",
    "    datasetArn = dataset_arn,\n",
    "    dataSource = {\n",
    "        \"dataLocation\": \"s3://{}/{}\".format(bucket, filename_ratings)\n",
    "    },\n",
    "    roleArn = role_arn\n",
    ")\n",
    "\n",
    "dataset_import_job_arn = create_dataset_import_job_response['datasetImportJobArn']\n",
    "print(json.dumps(create_dataset_import_job_response, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wait for Dataset Import Job Run to Have ACTIVE Status (should take about 15 min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetImportJob: CREATE PENDING\n",
      "DatasetImportJob: CREATE IN_PROGRESS\n",
      "DatasetImportJob: CREATE IN_PROGRESS\n",
      "DatasetImportJob: CREATE IN_PROGRESS\n",
      "DatasetImportJob: CREATE IN_PROGRESS\n",
      "DatasetImportJob: CREATE IN_PROGRESS\n",
      "DatasetImportJob: CREATE IN_PROGRESS\n",
      "DatasetImportJob: CREATE IN_PROGRESS\n",
      "DatasetImportJob: CREATE IN_PROGRESS\n",
      "DatasetImportJob: CREATE IN_PROGRESS\n",
      "DatasetImportJob: CREATE IN_PROGRESS\n",
      "DatasetImportJob: CREATE IN_PROGRESS\n",
      "DatasetImportJob: CREATE IN_PROGRESS\n",
      "DatasetImportJob: ACTIVE\n",
      "CPU times: user 96.1 ms, sys: 7.25 ms, total: 103 ms\n",
      "Wall time: 13min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "status = None\n",
    "max_time = time.time() + 3*60*60 # 3 hours\n",
    "while time.time() < max_time:\n",
    "    describe_dataset_import_job_response = personalize.describe_dataset_import_job(\n",
    "        datasetImportJobArn = dataset_import_job_arn\n",
    "    )\n",
    "    \n",
    "    dataset_import_job = describe_dataset_import_job_response[\"datasetImportJob\"]\n",
    "    if \"latestDatasetImportJobRun\" not in dataset_import_job:\n",
    "        status = dataset_import_job[\"status\"]\n",
    "        print(\"DatasetImportJob: {}\".format(status))\n",
    "    else:\n",
    "        status = dataset_import_job[\"latestDatasetImportJobRun\"][\"status\"]\n",
    "        print(\"LatestDatasetImportJobRun: {}\".format(status))\n",
    "    \n",
    "    if status == \"ACTIVE\" or status == \"CREATE FAILED\":\n",
    "        break\n",
    "        \n",
    "    time.sleep(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Solution\n",
    "\n",
    "In order to train a model which can serve recommendations, you need to first create a solution in Amazon Personalize and then create a solution version to kick of the training job.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:personalize:::recipe/aws-hrnn\n",
      "arn:aws:personalize:::recipe/aws-hrnn-coldstart\n",
      "arn:aws:personalize:::recipe/aws-hrnn-metadata\n",
      "arn:aws:personalize:::recipe/aws-personalized-ranking\n",
      "arn:aws:personalize:::recipe/aws-popularity-count\n",
      "arn:aws:personalize:::recipe/aws-sims\n"
     ]
    }
   ],
   "source": [
    "recipe_list = personalize.list_recipes()\n",
    "for recipe in recipe_list['recipes']:\n",
    "    print(recipe['recipeArn'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many recipes for different scenarios. In this example, we only have interactions data, so we will choose one from the basic recipes.\n",
    "\n",
    "| Feasible? | Recipe | Description \n",
    "|-------- | -------- |:------------\n",
    "| Y | aws-popularity-count | Calculates popularity of items based on count of events against that item in user-item interactions dataset.\n",
    "| Y | aws-hrnn | Predicts items a user will interact with. A hierarchical recurrent neural network which can model the temporal order of user-item interactions.\n",
    "| N - requires meta data | aws-hrnn-metadata | Predicts items a user will interact with. HRNN with additional features derived from contextual (user-item interaction metadata), user medata (user dataset) and item metadata (item dataset)\n",
    "| N - for bandits and requires meta data | aws-hrnn-coldstart | Predicts items a user will interact with. HRNN-metadata with with personalized exploration of new items.\n",
    "| N - for item-based queries | aws-sims | Computes items similar to a given item based on co-occurrence of item in same user history in user-item interaction dataset\n",
    "| N - for reranking a short list | aws-personalized-ranking | Reranks a list of items for a user. Trains on user-item interactions dataset. \n",
    "\n",
    "\n",
    "We (or autoML) can run all of these basic recipes and choose the best-performing model from internal metrics. We recommend comparisons, especially with popularity-baseline, to see the lifts in metrics via personalization. However, in this demo, we will pick one recipe - aws-sims, to illustrate smell tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipe_arn = \"arn:aws:personalize:::recipe/aws-sims\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"solutionArn\": \"arn:aws:personalize:us-east-1:190920649605:solution/DEMO-sims-solution-20m\",\n",
      "  \"ResponseMetadata\": {\n",
      "    \"RequestId\": \"03df6388-c050-4f89-8b79-88d298a5cc3b\",\n",
      "    \"HTTPStatusCode\": 200,\n",
      "    \"HTTPHeaders\": {\n",
      "      \"content-type\": \"application/x-amz-json-1.1\",\n",
      "      \"date\": \"Mon, 06 Jan 2020 13:27:43 GMT\",\n",
      "      \"x-amzn-requestid\": \"03df6388-c050-4f89-8b79-88d298a5cc3b\",\n",
      "      \"content-length\": \"92\",\n",
      "      \"connection\": \"keep-alive\"\n",
      "    },\n",
      "    \"RetryAttempts\": 0\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "create_solution_response = personalize.create_solution(\n",
    "    name = \"DEMO-sims-solution-\"+suffix,\n",
    "    datasetGroupArn = dataset_group_arn,\n",
    "    recipeArn = recipe_arn,\n",
    ")\n",
    "\n",
    "solution_arn = create_solution_response['solutionArn']\n",
    "print(json.dumps(create_solution_response, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"solutionVersionArn\": \"arn:aws:personalize:us-east-1:190920649605:solution/DEMO-sims-solution-20m/0e6b5c1b\",\n",
      "  \"ResponseMetadata\": {\n",
      "    \"RequestId\": \"d3488866-41f3-43cc-9e97-ac25b9743a70\",\n",
      "    \"HTTPStatusCode\": 200,\n",
      "    \"HTTPHeaders\": {\n",
      "      \"content-type\": \"application/x-amz-json-1.1\",\n",
      "      \"date\": \"Mon, 06 Jan 2020 13:27:44 GMT\",\n",
      "      \"x-amzn-requestid\": \"d3488866-41f3-43cc-9e97-ac25b9743a70\",\n",
      "      \"content-length\": \"108\",\n",
      "      \"connection\": \"keep-alive\"\n",
      "    },\n",
      "    \"RetryAttempts\": 0\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "create_solution_version_response = personalize.create_solution_version(\n",
    "    solutionArn = solution_arn\n",
    ")\n",
    "\n",
    "solution_version_arn = create_solution_version_response['solutionVersionArn']\n",
    "print(json.dumps(create_solution_version_response, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now wait for Solution Version to Have ACTIVE Status, this can take about 40 minutes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SolutionVersion: CREATE PENDING\n",
      "SolutionVersion: CREATE IN_PROGRESS\n",
      "SolutionVersion: CREATE IN_PROGRESS\n",
      "SolutionVersion: CREATE IN_PROGRESS\n",
      "SolutionVersion: CREATE IN_PROGRESS\n",
      "SolutionVersion: CREATE IN_PROGRESS\n",
      "SolutionVersion: CREATE IN_PROGRESS\n",
      "SolutionVersion: CREATE IN_PROGRESS\n",
      "SolutionVersion: CREATE IN_PROGRESS\n",
      "SolutionVersion: CREATE IN_PROGRESS\n",
      "SolutionVersion: CREATE IN_PROGRESS\n",
      "SolutionVersion: CREATE IN_PROGRESS\n",
      "SolutionVersion: CREATE IN_PROGRESS\n",
      "SolutionVersion: CREATE IN_PROGRESS\n",
      "SolutionVersion: CREATE IN_PROGRESS\n",
      "SolutionVersion: CREATE IN_PROGRESS\n",
      "SolutionVersion: CREATE IN_PROGRESS\n",
      "SolutionVersion: CREATE IN_PROGRESS\n",
      "SolutionVersion: CREATE IN_PROGRESS\n",
      "SolutionVersion: CREATE IN_PROGRESS\n",
      "SolutionVersion: CREATE IN_PROGRESS\n",
      "SolutionVersion: CREATE IN_PROGRESS\n",
      "SolutionVersion: CREATE IN_PROGRESS\n",
      "SolutionVersion: CREATE IN_PROGRESS\n",
      "SolutionVersion: CREATE IN_PROGRESS\n",
      "SolutionVersion: CREATE IN_PROGRESS\n",
      "SolutionVersion: CREATE IN_PROGRESS\n",
      "SolutionVersion: CREATE IN_PROGRESS\n",
      "SolutionVersion: CREATE IN_PROGRESS\n",
      "SolutionVersion: CREATE IN_PROGRESS\n",
      "SolutionVersion: CREATE IN_PROGRESS\n",
      "SolutionVersion: CREATE IN_PROGRESS\n",
      "SolutionVersion: CREATE IN_PROGRESS\n",
      "SolutionVersion: CREATE IN_PROGRESS\n",
      "SolutionVersion: CREATE IN_PROGRESS\n",
      "SolutionVersion: CREATE IN_PROGRESS\n",
      "SolutionVersion: CREATE IN_PROGRESS\n",
      "SolutionVersion: ACTIVE\n",
      "CPU times: user 246 ms, sys: 11.2 ms, total: 257 ms\n",
      "Wall time: 37min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "status = None\n",
    "max_time = time.time() + 3*60*60 # 3 hours\n",
    "while time.time() < max_time:\n",
    "    describe_solution_version_response = personalize.describe_solution_version(\n",
    "        solutionVersionArn = solution_version_arn\n",
    "    )\n",
    "    status = describe_solution_version_response[\"solutionVersion\"][\"status\"]\n",
    "    print(\"SolutionVersion: {}\".format(status))\n",
    "    \n",
    "    if status == \"ACTIVE\" or status == \"CREATE FAILED\":\n",
    "        break\n",
    "        \n",
    "    time.sleep(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Metrics of Solution\n",
    "\n",
    "Once your training is finished, you can get various evaluation metrics for your model. An explanation of the evaluation metrics are provided at https://docs.aws.amazon.com/personalize/latest/dg/working-with-training-metrics.html\n",
    "\n",
    "For example, suppose we recommend four items and two of them are relevant, $r=[0,1,0,1]$. In this case, the metrics are:\n",
    "\n",
    "|Name\t|Example\t|Explanation\n",
    "|:------|:----------|:----------\n",
    "|Precision@K\t|$\\frac{2}{4} = 0.5$\t|Total relevant items divided by total recommended items.\n",
    "|Mean reciprocal ranks (MRR@K)\t|${\\rm mean}(\\frac{1}{2} + \\frac{1}{4}) = 0.375$\t|Considers positional effects by computing the mean of the inverse positions of all relevant items.\n",
    "|Normalized discounted cumulative gains (NDCG@K)\t|$\\frac{\\frac{1}{\\log(1 + 2)} + \\frac{1}{\\log(1 + 4)}}{\\frac{1}{\\log(1 + 1)} + \\frac{1}{\\log(1 + 2)}} = 0.65$\t|Considers positional effects by applying inverse logarithmic weights based on the positions of relevant items, normalized by the largest possible scores from ideal recommendations.\n",
    "|Average precision (AP@K)\t|${\\rm mean}(\\frac{1}{2} + \\frac{2}{4}) = 0.5$\t|Average precision@K where K is the position of every relevant item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"solutionVersionArn\": \"arn:aws:personalize:us-east-1:190920649605:solution/DEMO-sims-solution-20m/0e6b5c1b\",\n",
      "  \"metrics\": {\n",
      "    \"coverage\": 0.3084,\n",
      "    \"mean_reciprocal_rank_at_25\": 0.0226,\n",
      "    \"normalized_discounted_cumulative_gain_at_10\": 0.0315,\n",
      "    \"normalized_discounted_cumulative_gain_at_25\": 0.044,\n",
      "    \"normalized_discounted_cumulative_gain_at_5\": 0.0241,\n",
      "    \"precision_at_10\": 0.0053,\n",
      "    \"precision_at_25\": 0.0042,\n",
      "    \"precision_at_5\": 0.0063\n",
      "  },\n",
      "  \"ResponseMetadata\": {\n",
      "    \"RequestId\": \"fc08fe4c-851d-4e5d-abcb-5ad07c8c5f73\",\n",
      "    \"HTTPStatusCode\": 200,\n",
      "    \"HTTPHeaders\": {\n",
      "      \"content-type\": \"application/x-amz-json-1.1\",\n",
      "      \"date\": \"Mon, 06 Jan 2020 14:04:48 GMT\",\n",
      "      \"x-amzn-requestid\": \"fc08fe4c-851d-4e5d-abcb-5ad07c8c5f73\",\n",
      "      \"content-length\": \"405\",\n",
      "      \"connection\": \"keep-alive\"\n",
      "    },\n",
      "    \"RetryAttempts\": 0\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "get_metrics_response = personalize.get_solution_metrics(\n",
    "    solutionVersionArn = solution_version_arn\n",
    ")\n",
    "\n",
    "print(json.dumps(get_metrics_response, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create and Wait for Campaign\n",
    "\n",
    "In order to deploy the solution version and serve predictions, we need to define a campaign in Amazon Personalize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"campaignArn\": \"arn:aws:personalize:us-east-1:190920649605:campaign/DEMO-sims-campaign-20m\",\n",
      "  \"ResponseMetadata\": {\n",
      "    \"RequestId\": \"a110468a-12bc-43e6-9b82-c2d2de08571a\",\n",
      "    \"HTTPStatusCode\": 200,\n",
      "    \"HTTPHeaders\": {\n",
      "      \"content-type\": \"application/x-amz-json-1.1\",\n",
      "      \"date\": \"Mon, 06 Jan 2020 14:04:48 GMT\",\n",
      "      \"x-amzn-requestid\": \"a110468a-12bc-43e6-9b82-c2d2de08571a\",\n",
      "      \"content-length\": \"92\",\n",
      "      \"connection\": \"keep-alive\"\n",
      "    },\n",
      "    \"RetryAttempts\": 0\n",
      "  }\n",
      "}\n",
      "CPU times: user 400 µs, sys: 3.66 ms, total: 4.06 ms\n",
      "Wall time: 47.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "create_campaign_response = personalize.create_campaign(\n",
    "    name = \"DEMO-sims-campaign-\"+suffix,\n",
    "    solutionVersionArn = solution_version_arn,\n",
    "    minProvisionedTPS = 2,    \n",
    ")\n",
    "\n",
    "campaign_arn = create_campaign_response['campaignArn']\n",
    "print(json.dumps(create_campaign_response, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wait for Campaign to Have ACTIVE Status (Takes about 10 minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Campaign: CREATE PENDING\n",
      "Campaign: CREATE IN_PROGRESS\n",
      "Campaign: CREATE IN_PROGRESS\n",
      "Campaign: CREATE IN_PROGRESS\n",
      "Campaign: CREATE IN_PROGRESS\n",
      "Campaign: CREATE IN_PROGRESS\n",
      "Campaign: CREATE IN_PROGRESS\n",
      "Campaign: CREATE IN_PROGRESS\n",
      "Campaign: CREATE IN_PROGRESS\n",
      "Campaign: ACTIVE\n",
      "CPU times: user 57.7 ms, sys: 2.59 ms, total: 60.3 ms\n",
      "Wall time: 9min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "status = None\n",
    "max_time = time.time() + 3*60*60 # 3 hours\n",
    "while time.time() < max_time:\n",
    "    describe_campaign_response = personalize.describe_campaign(\n",
    "        campaignArn = campaign_arn\n",
    "    )\n",
    "    status = describe_campaign_response[\"campaign\"][\"status\"]\n",
    "    print(\"Campaign: {}\".format(status))\n",
    "    \n",
    "    if status == \"ACTIVE\" or status == \"CREATE FAILED\":\n",
    "        break\n",
    "        \n",
    "    time.sleep(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To aid in interpretation, lets look at some items \n",
    "\n",
    "To better interpret the results, we need to map the item id to a movie title. We can do this using the movies.csv file provided by the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ITEM_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>Comedy|Drama|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      title  \\\n",
       "ITEM_ID                                       \n",
       "1                          Toy Story (1995)   \n",
       "2                            Jumanji (1995)   \n",
       "3                   Grumpier Old Men (1995)   \n",
       "4                  Waiting to Exhale (1995)   \n",
       "5        Father of the Bride Part II (1995)   \n",
       "\n",
       "                                               genre  \n",
       "ITEM_ID                                               \n",
       "1        Adventure|Animation|Children|Comedy|Fantasy  \n",
       "2                         Adventure|Children|Fantasy  \n",
       "3                                     Comedy|Romance  \n",
       "4                               Comedy|Drama|Romance  \n",
       "5                                             Comedy  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies = pd.read_csv('./ml-20m/movies.csv', header=0, names=['ITEM_ID','title','genre'])\n",
    "movies=movies.set_index('ITEM_ID')\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we pick a couple of items and look at if items found are generally of similar genres. Note, the model did not use this meta-data (genre) for training, this is a sanity or smell test to see if the model discovered similar items that 'make sense'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similar movies like Toy Story"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ITEM_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>Lion King, The (1994)</td>\n",
       "      <td>Adventure|Animation|Children|Drama|Musical|IMAX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>Blue Chips (1994)</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>783</th>\n",
       "      <td>Hunchback of Notre Dame, The (1996)</td>\n",
       "      <td>Animation|Children|Drama|Musical|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2716</th>\n",
       "      <td>Ghostbusters (a.k.a. Ghost Busters) (1984)</td>\n",
       "      <td>Action|Comedy|Sci-Fi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1073</th>\n",
       "      <td>Willy Wonka &amp; the Chocolate Factory (1971)</td>\n",
       "      <td>Children|Comedy|Fantasy|Musical</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              title  \\\n",
       "ITEM_ID                                               \n",
       "364                           Lion King, The (1994)   \n",
       "424                               Blue Chips (1994)   \n",
       "783             Hunchback of Notre Dame, The (1996)   \n",
       "2716     Ghostbusters (a.k.a. Ghost Busters) (1984)   \n",
       "1073     Willy Wonka & the Chocolate Factory (1971)   \n",
       "\n",
       "                                                   genre  \n",
       "ITEM_ID                                                   \n",
       "364      Adventure|Animation|Children|Drama|Musical|IMAX  \n",
       "424                                                Drama  \n",
       "783             Animation|Children|Drama|Musical|Romance  \n",
       "2716                                Action|Comedy|Sci-Fi  \n",
       "1073                     Children|Comedy|Fantasy|Musical  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "personalize_runtime = boto3.client('personalize-runtime')\n",
    "\n",
    "rec_response = personalize_runtime.get_recommendations(\n",
    "        campaignArn = campaign_arn,\n",
    "        itemId = str(1)\n",
    "    )\n",
    "rec_items = [int(x['itemId']) for x in rec_response['itemList']]\n",
    "movies.loc[rec_items[:5]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similar movies like Jumanji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_response = personalize_runtime.get_recommendations(\n",
    "        campaignArn = campaign_arn,\n",
    "        itemId = str(2)\n",
    "    )\n",
    "rec_items = [int(x['itemId']) for x in rec_response['itemList']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ITEM_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45081</th>\n",
       "      <td>Silent Hill (2006)</td>\n",
       "      <td>Fantasy|Horror|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>Santa Clause, The (1994)</td>\n",
       "      <td>Comedy|Drama|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>Waterworld (1995)</td>\n",
       "      <td>Action|Adventure|Sci-Fi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>Mrs. Doubtfire (1993)</td>\n",
       "      <td>Comedy|Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Dangerous Minds (1995)</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            title                    genre\n",
       "ITEM_ID                                                   \n",
       "45081          Silent Hill (2006)  Fantasy|Horror|Thriller\n",
       "317      Santa Clause, The (1994)     Comedy|Drama|Fantasy\n",
       "208             Waterworld (1995)  Action|Adventure|Sci-Fi\n",
       "500         Mrs. Doubtfire (1993)             Comedy|Drama\n",
       "31         Dangerous Minds (1995)                    Drama"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies.loc[rec_items[:5]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Congratulations, we are now ready to use this campaign endpoint within our chatbot!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'arn:aws:personalize:us-east-1:190920649605:campaign/DEMO-sims-campaign-20m'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "campaign_arn"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
